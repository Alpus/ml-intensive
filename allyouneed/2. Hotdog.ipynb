{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучаем машины"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В сериале \"Силиконовая долина\" один из героев сделал новое приложение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.lib.display import YouTubeVideo\n",
    "YouTubeVideo('mrk95jFVKqY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приложение бесполезное, но веселое и на нем можно просто показать полынй цикл обучения своей модели с нуля. Начнем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам понадобится несколько библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # используем для работы с файлами и папками\n",
    "from random import random\n",
    "\n",
    "import torch  # библиотека для нейронок\n",
    "from IPython.display import clear_output  # функция удаляющая вывод чтобы не мусорить на экране.\n",
    "from PIL import Image  # библиотека для работы с картинками\n",
    "from matplotlib import pyplot as plt  # графики\n",
    "from torch import nn, optim  # другие подмодули дял нейронок и их обучения\n",
    "from torch.utils.data import Dataset, DataLoader  # другие вспомогательные модули torch-а\n",
    "from torchvision import transforms, models  # вспомогательные функции для оьработки изображений\n",
    "from tqdm import tqdm, trange  # библиотека дял отображения полоски загрузки\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # убирает лишние выводы с экрана"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы не делаете сложных экспериментов, то обучать сетки могут даже дети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = nn.Linear(10, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот так создается линейная модель в PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_model = nn.Sequential(\n",
    "    nn.Linear(10, 5),\n",
    "    nn.ELU(),\n",
    "    nn.Linear(5, 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот так мы сделали модель, которая последовательно применяет два линейных слоя с активацией между ними."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обучения используются встроенные оптимизаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(sequence_model.parameters(), lr=1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Один шаг оптимизации:\n",
    "\n",
    "1) Прогон модели от входа до результата\n",
    "\n",
    "2) Высчитывание градиентов функции ошибки\n",
    "\n",
    "3) Шаг (вычитание градиентов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.rand((1, 10), requires_grad=True)\n",
    "real_answer = input_tensor * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = sequence_model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = torch.mean(torch.abs(predictions - real_answer))\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь ошибка стала чуть меньше. Сделать так много раз - сеть обучится."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = torch.mean(torch.abs(sequence_model(input_tensor) - real_answer))\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь к задаче. Начнем с данных. Сейчас они предзагружены и лежат по папкам, пути до которых написаны ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '/workdir/data/'\n",
    "IMAGES_FOLDER = os.path.join(DATA_FOLDER, 'images')\n",
    "\n",
    "HOTDOGS_FOLDER = os.path.join(IMAGES_FOLDER, 'hotdogs')\n",
    "HOTDOGS_FOLDER_TRAIN = os.path.join(HOTDOGS_FOLDER, 'train')\n",
    "HOTDOGS_FOLDER_VAL = os.path.join(HOTDOGS_FOLDER, 'validation')\n",
    "HOTDOGS_FOLDER_TEST = os.path.join(HOTDOGS_FOLDER, 'test')\n",
    "\n",
    "BURGERS_FOLDER = os.path.join(IMAGES_FOLDER, 'burgers')\n",
    "BURGERS_FOLDER_TRAIN = os.path.join(BURGERS_FOLDER, 'train')\n",
    "BURGERS_FOLDER_VAL = os.path.join(BURGERS_FOLDER, 'validation')\n",
    "BURGERS_FOLDER_TEST = os.path.join(BURGERS_FOLDER, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hold out\n",
    "\n",
    "Классическое разделение данных - train, validation, test. \n",
    "\n",
    "train - данные на которых модель учится\n",
    "\n",
    "validation - данные на которые мы смотрим во вреям обучения, чтобы контролировать, как модель работает с картинками, на которых не обучалась. Сеть на них запускается, но не учится.\n",
    "\n",
    "test - набор данных, на котором модель тестируется в самом конце. Он - финальный тест для нашей модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Немного кода для считывания картинок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FolderDataset:\n",
    "    def __init__(self, folder, transform=None):\n",
    "        self.files = [os.path.join(folder, image_path) for image_path in os.listdir(folder)]\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        result = Image.open(self.files[idx]).convert('RGB')\n",
    "        \n",
    "        if self.transform is None:\n",
    "            return result\n",
    "        else:\n",
    "            return self.transform(result)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выглядит сложно, но на самом деле это просто класс, который можно попросить загрузить картинку под каким-то номером."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на пару примеров из наших данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotdogs_images = FolderDataset(HOTDOGS_FOLDER_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotdogs_images[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burgers_images = FolderDataset(BURGERS_FOLDER_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "burgers_images[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я просто взял и скачал по 200 картинок из гугла по запросу burger и hotdog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь напишем нашу сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HotdogClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.seq = nn.Sequential(  # будет вызывать поочереди все переданные слои\n",
    "            nn.Conv2d(3, 16, (3, 3)),  # 256 x 256 x 3 -> 256 x 256 x 16\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(16, 32, (5, 5), stride=2, padding=2),  # 256 x 256 x 16 -> 128 x 128 x 32\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(32, 64, (5, 5), stride=2, padding=2),  # 128 x 128 x 32 -> 64 x 64 x 64\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(64, 128, (5, 5), stride=2, padding=2),  # 64 x 64 x 64 -> 32 x 32 x 128\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(128, 256, (5, 5), stride=2, padding=2),  # 32 x 32 x 128 -> 16 x 16 x 256\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.fc = nn.Linear(256 * 8 * 8, 1)  # 16 x 16 x 256 -> 1\n",
    "    \n",
    "    def forward(self, x):  # функция получающая вход и выдающая результат\n",
    "        x = self.seq(x)\n",
    "        x = x.view(-1, 256 * 8 * 8)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_smoothing(values, alpha=0.8):  # дополнительная функция, чтобы графики выводились более плавно\n",
    "    smoothed_values = [values[0]]\n",
    "    for x in values[1:]:\n",
    "        smoothed_values.append(smoothed_values[-1] * alpha + x * (1 - alpha))\n",
    "    \n",
    "    return smoothed_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, hotdogs_train, hotdogs_val, burgers_train, burgers_val, epoch_count=5):\n",
    "    batch_size = 4\n",
    "    \n",
    "    # подготавливаем загрузку данных в нужном формате\n",
    "    hotdogs_train_loader = DataLoader(hotdogs_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    burgers_train_loader = DataLoader(burgers_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    \n",
    "    mse_loss = nn.MSELoss()  # функция ошибки - то что мы хотим уменьшать. Цель нашей модели.\n",
    "    \n",
    "    log = []\n",
    "    log_val = []\n",
    "    \n",
    "    for epoch_num in range(epoch_count):\n",
    "        title = 'Epoch {}/{}'.format(epoch_num + 1, epoch_count)\n",
    "        for step_num, (hotdog_tensor, burger_tensor) in tqdm(enumerate(zip(hotdogs_train_loader, burgers_train_loader)), desc=title, total=len(hotdogs_train_loader)):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # получаем предсказания\n",
    "            predictions = nn.functional.sigmoid(model(torch.cat([hotdog_tensor, burger_tensor])))\n",
    "            #  получаем настоящие ответы, где хотдоги, а где нет\n",
    "            answers = torch.cat([torch.ones(batch_size), torch.zeros(batch_size)])[..., None]\n",
    "\n",
    "            loss = mse_loss(predictions, answers)  # вычисляем ошибку\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()  # пытаемся ее уменьшить\n",
    "            \n",
    "            # рисуем гарфики ошибок\n",
    "            if step_num % 2 == 0:\n",
    "                hotdogs_val_loader = DataLoader(hotdogs_val, batch_size=batch_size, shuffle=True)\n",
    "                burgers_val_loader = DataLoader(burgers_val, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "                val_predictions = nn.functional.sigmoid(model(torch.cat([next(iter(hotdogs_val_loader)), next(iter(burgers_val_loader))])))\n",
    "                val_answers = torch.cat([torch.ones(batch_size), torch.zeros(batch_size)])[..., None]\n",
    "\n",
    "                loss_val = mse_loss(val_predictions, val_answers)\n",
    "\n",
    "                log.append(loss.detach_())\n",
    "                log_val.append(loss_val.detach_())\n",
    "                \n",
    "                clear_output()\n",
    "                plt.plot(exponential_smoothing(log), color='blue', label='training loss')\n",
    "                plt.plot(exponential_smoothing(log_val), color='red', label='validation loss')\n",
    "                plt.legend()\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И, конечно, функция для финального теста. Просто запускаем нашу модель на всех тестовых изображениях и считаем долю правильных ответов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, hotdogs_test, burgers_test):\n",
    "    hotdogs_test_loader = DataLoader(hotdogs_test, batch_size=1)\n",
    "    burgers_test_loader = DataLoader(burgers_test, batch_size=1)\n",
    "    \n",
    "    log = []\n",
    "    total = len(hotdogs_test_loader)\n",
    "    \n",
    "    for hotdog_tensor, burger_tensor in tqdm(zip(hotdogs_test_loader, burgers_test_loader), total=total):\n",
    "        predictions = model(torch.cat([hotdog_tensor, burger_tensor]))\n",
    "        answers = torch.cat([torch.ones(1), torch.zeros(1)])[..., None]\n",
    "\n",
    "        is_hotdog = predictions > 0\n",
    "        accuracy = is_hotdog.type(torch.int8) == answers.type(torch.int8)\n",
    "        log.append(accuracy)\n",
    "            \n",
    "    return torch.cat(log).type(torch.float32).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ставим модель обучаться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_resize = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])  # меняем размер данных и превращаем в тензор - способ представления изображений для сеток.\n",
    "\n",
    "# применяем трансформацию к датасетам\n",
    "hotdogs_train = FolderDataset(HOTDOGS_FOLDER_TRAIN, transform_resize)\n",
    "hotdogs_val = FolderDataset(HOTDOGS_FOLDER_VAL, transform_resize)\n",
    "hotdogs_test = FolderDataset(HOTDOGS_FOLDER_TEST, transform_resize)\n",
    "\n",
    "burgers_train = FolderDataset(BURGERS_FOLDER_TRAIN, transform_resize)\n",
    "burgers_val = FolderDataset(BURGERS_FOLDER_VAL, transform_resize)\n",
    "burgers_test = FolderDataset(BURGERS_FOLDER_TEST, transform_resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotdog_classifier = HotdogClassifier()  # создаем экземляр сетки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на ее качество, на момент, когда оан еще не обучалась."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(hotdog_classifier, hotdogs_test, burgers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(hotdog_classifier.parameters(), lr=1e-4, amsgrad=True)  # оптимизатор - написанный за нас способ оптимизации весов нашей сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поставим обучаться сеть.\n",
    "\n",
    "* Можно задать вопросы.\n",
    "* Можно передохнуть (так желают все ресерчеры)\n",
    "* Что такое loss?\n",
    "* Почему он падает?\n",
    "* Как связаны loss валидации и обучения?\n",
    "* Как выбираюсь архитектуру сети?\n",
    "* Как работают с данными?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(hotdog_classifier, optimizer, hotdogs_train, hotdogs_val, burgers_train, burgers_val, epoch_count=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(hotdog_classifier, hotdogs_test, burgers_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили результат обученной сети. К слову, она переобучилась! Это когда модель слишком зациклена на данных, котоыре она видела и не смотрит на общую картину. Она просто запомнила данные для обучения, но не обнаружила достаточно много паттернов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем отражать картинки по горизонтали и немного портить их. Это называется аугментацией. Данных у нас очень мало. Хотя кажется, что порча картинок ухудшит качество, в реальности так делают очень часто. Делов . том что мы таким образом как бы \"бесплатно\" создаем новые картинки. Больше датасет - лучше обучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, mean=0, std=0.05, p=0.1\n",
    "            ):\n",
    "    if random() < p:\n",
    "        noise = x.clone().normal_(mean, std)\n",
    "        x = (x + noise).clamp(0, 1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_augment = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    gaussian,\n",
    "])\n",
    "\n",
    "hotdogs_train = FolderDataset(HOTDOGS_FOLDER_TRAIN, transform_augment)\n",
    "hotdogs_train = FolderDataset(HOTDOGS_FOLDER_TRAIN, transform_augment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms.functional.to_pil_image(hotdogs_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotdog_classifier_with_flip = HotdogClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(hotdog_classifier_with_flip.parameters(), lr=1e-4, amsgrad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(hotdog_classifier_with_flip, optimizer, hotdogs_train, hotdogs_val, burgers_train, burgers_val, epoch_count=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(hotdog_classifier_with_flip, hotdogs_test, burgers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotdog_classifier_with_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "\n",
    "def show_featuremap(image, model, layer, image_size=128):\n",
    "    tensor = hotdogs_test[0]\n",
    "    transforms.functional.to_pil_image(tensor)\n",
    "    featuremap_maker = list(hotdog_classifier_with_flip.children())[0][:layer + 1]\n",
    "    feature_map = featuremap_maker(tensor[None, ...])\n",
    "        \n",
    "    big_image = Image.new('RGB', (4 * image_size, (feature_map.size(1) // 4) * image_size))\n",
    "    \n",
    "    for feature_num in range(feature_map.size(1)):\n",
    "        row_num = feature_num % 4\n",
    "        col_num = feature_num // 4\n",
    "        \n",
    "        small_image = feature_map[:, feature_num]\n",
    "        big_image.paste(\n",
    "            transforms.functional.resize(\n",
    "                transforms.functional.to_pil_image(\n",
    "                    feature_map[:, feature_num]\n",
    "                ),\n",
    "                (image_size, image_size),\n",
    "                interpolation=0\n",
    "            ),\n",
    "            (row_num * (image_size), col_num * (image_size))\n",
    "        )\n",
    "    \n",
    "    return big_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Промежуточные представления картинок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_featuremap(hotdogs_test, hotdog_classifier_with_flip, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вторая модель либо лучше, либо хуже. Ресерч - это в первую очередь эксперименты. Иногда идеи просто не работают."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По сути мы прошли полный цикл создания простейшей модели: от скачивания данных до обученной сети. Естественно, расчитывать на идеальное качество за такое время не приходится, но, на минуточку, мы только что воспроизвели сеть из одного из самых популярных в мире сериалов про технарей!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте подергать разные настройки или может быть у вас есть какая-то идея, но вы не знаете как ее написать на питоне. Скажите мне и мы попробуем поэкспериментировать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
